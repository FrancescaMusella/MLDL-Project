{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescaMusella/MLDL-Project/blob/main/centralized_finalversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as F\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "loR2UtR8Z1SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "id": "ObGUKVJncju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOHznMM1NnNm"
      },
      "outputs": [],
      "source": [
        "#transformation of CIFAR100\n",
        "transform = T.Compose([\n",
        "    T.Resize((32, 32)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "train_val=CIFAR100(root='.data/', train=True, download=True, transform=transform)\n",
        "test=CIFAR100(root='.data/', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "7TzW8O-4LJkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qvPMWc-FaBB"
      },
      "outputs": [],
      "source": [
        "#train-validation-test split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "targets = train_val.targets\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(targets)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train = torch.utils.data.Subset(train_val, train_indices)\n",
        "val = torch.utils.data.Subset(train_val, val_indices)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
        "val_loader= torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ViT-S/16\n",
        "!git clone https://github.com/facebookresearch/dino.git\n",
        "!ls"
      ],
      "metadata": {
        "id": "uH4OhUbbbQyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "vits16_original = torch.hub.load('facebookresearch/dino:main', 'dino_vits16', pretrained=True).to(device)\n",
        "vits16_new=copy.deepcopy(vits16_original)\n",
        "print(vits16_new)"
      ],
      "metadata": {
        "id": "KUbiE55wbVPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTh4zLIFhlIG"
      },
      "outputs": [],
      "source": [
        "#change of the head and freezing of layers\n",
        "vits16_new.head = torch.nn.Linear(in_features=384,\n",
        "                    out_features=100,\n",
        "                    bias=True).to(device)\n",
        "\n",
        "for name, param in vits16_new.named_parameters():\n",
        "    if \"head\" not in name and \"patch_embed\" not in name and 'proj' not in name and 'pos_drop' not in name and 'attn' not in name:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "vits16_self_sgd=copy.deepcopy(vits16_new)\n",
        "vits16_sparse=copy.deepcopy(vits16_new)\n",
        "\n",
        "print(vits16_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMu4Gchu2zXZ"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_NhoDDy_pcz"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "        features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "        outputs = model.head(features)\n",
        "\n",
        "        loss=criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6no0CcJ9BSkm"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "            features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "            outputs = model.head(features)\n",
        "            loss=criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Validation Loss: {val_loss:.6f} Acc: {val_accuracy:.2f}%')\n",
        "    return val_accuracy, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0zVQ-nTEWDO"
      },
      "outputs": [],
      "source": [
        "#Vanilla SGDM grid search\n",
        "best_acc = 0\n",
        "best_param=[0, 0, 0]\n",
        "\n",
        "learning_rates = [1e-3, 1e-4, 5e-4]\n",
        "weight_decay_values=[1e-3, 1e-4, 5e-4]\n",
        "num_epochs = 10\n",
        "\n",
        "lr_counter=0\n",
        "mt_counter=0\n",
        "x_acc=torch.zeros(len(learning_rates),len(weight_decay_values),num_epochs)\n",
        "x_loss=torch.zeros(len(learning_rates),len(weight_decay_values),num_epochs)\n",
        "for lr in learning_rates:\n",
        "    for weight_decay in weight_decay_values:\n",
        "        model=copy.deepcopy(vits16_new)\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
        "        scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            train(epoch, model, train_loader, loss_fn, optimizer)\n",
        "            scheduler.step()\n",
        "            val_accuracy, val_loss = validate(model, val_loader, loss_fn)\n",
        "\n",
        "            if val_accuracy > best_acc:\n",
        "                best_acc = val_accuracy\n",
        "                best_param[0]=lr\n",
        "                best_param[1]=weight_decay\n",
        "                best_param[2]=epoch\n",
        "\n",
        "\n",
        "            x_acc[lr_counter,mt_counter,epoch-1]=val_accuracy\n",
        "            x_loss[lr_counter,mt_counter,epoch-1]=val_loss\n",
        "        mt_counter+=1\n",
        "    mt_counter=0\n",
        "    lr_counter+=1\n",
        "\n",
        "print(f'Best validation accuracy: {best_acc:.2f}%')\n",
        "print(f'Best learning rate: {best_param[0]}')\n",
        "print(f'Weight decay: {best_param[1]}')\n",
        "print(f'Best epoch: {best_param[2]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQNLbaDDThye"
      },
      "outputs": [],
      "source": [
        "colors=['green', 'orange', 'blue']\n",
        "labels=['lr=1e-3', 'lr=1e-4', 'lr=5e-4']\n",
        "n_epoch=10\n",
        "fig, (ax1, ax2, ax3) = plt.subplots( 1, 3,figsize=(10,5))\n",
        "\n",
        "for i in range (0,3):\n",
        "  ax1.plot(x_acc[i,0,:], label = labels[i], color=colors[i])\n",
        "ax1.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.grid(True)\n",
        "ax1.set_title('Val_accuracy Weight decay=1e-3')\n",
        "ax1.legend()\n",
        "for i in range (0,3):\n",
        "  ax2.plot(x_acc[i,1,:], label = labels[i], color=colors[i])\n",
        "ax2.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.grid(True)\n",
        "ax2.set_title('Val_accuracy Weight decay=1e-4')\n",
        "ax2.legend()\n",
        "for i in range (0,3):\n",
        "  ax3.plot(x_acc[i,2,:], label = labels[i], color=colors[i])\n",
        "ax3.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Accuracy')\n",
        "ax3.grid(True)\n",
        "ax3.set_title('Val_accuracy Weight decay=5e-4')\n",
        "ax3.legend()\n",
        "plt.subplots_adjust(wspace=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiU8LVRob6LY"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots( 1, 3,figsize=(10,5))\n",
        "for i in range (0,3):\n",
        "  ax1.plot(x_loss[i,0,:], label = labels[i], color=colors[i])\n",
        "ax1.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.grid(True)\n",
        "ax1.set_title('Val_loss Weight decay=1e-3')\n",
        "ax1.legend()\n",
        "for i in range (0,3):\n",
        "  ax2.plot(x_loss[i,1,:], label = labels[i], color=colors[i])\n",
        "ax2.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.grid(True)\n",
        "ax2.set_title('Val_loss Weight decay=1e-4')\n",
        "ax2.legend()\n",
        "for i in range (0,3):\n",
        "  ax3.plot(x_loss[i,2,:], label = labels[i], color=colors[i])\n",
        "ax3.set_xticks(ticks=np.arange(n_epoch), labels=np.arange(1, n_epoch + 1))\n",
        "ax3.set_xlabel('Epoch')\n",
        "ax3.set_ylabel('Loss')\n",
        "ax3.grid(True)\n",
        "ax3.set_title('Val_loss Weight decay=5e-4')\n",
        "ax3.legend()\n",
        "plt.subplots_adjust(wspace=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CosineAnnealing scheduler\n",
        "num_epoch=20\n",
        "vits16=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler_cosine =torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "for epoch in range(1, num_epoch):\n",
        "  train(epoch, vits16, train_loader, loss_fn, optimizer)\n",
        "  val_accuracy, val_loss = validate(vits16, val_loader, loss_fn)\n",
        "  scheduler_cosine.step()"
      ],
      "metadata": {
        "id": "Dq8nxsYAmn2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear scheduler\n",
        "vits16=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler_linear = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.01, total_iters=200)\n",
        "\n",
        "for epoch in range(1, num_epoch):\n",
        "  train(epoch, vits16, train_loader, loss_fn, optimizer)\n",
        "  val_accuracy, val_loss = validate(vits16, val_loader, loss_fn)\n",
        "  scheduler_linear.step()"
      ],
      "metadata": {
        "id": "Um01guDPaFz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exponential scheduler\n",
        "vits16=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler_exp = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.9)\n",
        "\n",
        "for epoch in range(1, num_epoch):\n",
        "  train(epoch, vits16, train_loader, loss_fn, optimizer)\n",
        "  val_accuracy, val_loss = validate(vits16, val_loader, loss_fn)\n",
        "  scheduler_exp.step()"
      ],
      "metadata": {
        "id": "kWoXEgetaPMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#StepLR scheduler\n",
        "vits16=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "scheduler_step = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma = 0.9)\n",
        "\n",
        "for epoch in range(1, num_epoch):\n",
        "  train(epoch, vits16, train_loader, loss_fn, optimizer)\n",
        "  val_accuracy, val_loss = validate(vits16, val_loader, loss_fn)\n",
        "  scheduler_step.step()"
      ],
      "metadata": {
        "id": "iZ7vfZVfaQ21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test with the best hyper-parameters and scheduler\n",
        "n_epoch=50\n",
        "vits16=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "test_loss_vector=[]\n",
        "for epoch in range(1, n_epoch + 1):\n",
        "       train(epoch, vits16, train_loader, loss_fn, optimizer)\n",
        "       scheduler.step()\n",
        "       test_accuracy, test_loss = validate(vits16, test_loader, loss_fn)\n",
        "       test_loss_vector.append(test_loss)"
      ],
      "metadata": {
        "id": "XGeML0lXCWsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test_loss_vector, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, n_epoch, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, n_epoch, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test_loss Weight decay=5e-4, Learning rate=1e-4, Momentum=0.9')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bKCYQI0iDy56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of the mask\n",
        "def compute_fisher_mask(model, dataloader, sparsity, criterion):\n",
        "  fisher_scores = {}\n",
        "  prev_mask = {}\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for param in model.parameters():\n",
        "      if param.requires_grad:\n",
        "          fisher_scores[param] = torch.zeros_like(param.data)\n",
        "          prev_mask[param] = torch.ones_like(param.data)\n",
        "\n",
        "  for round in range(5):\n",
        "    for param in fisher_scores:\n",
        "        fisher_scores[param].zero_()\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "        features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "        outputs = model.head(features)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        for param in model.parameters():\n",
        "            if param.requires_grad and param.grad is not None:\n",
        "              fisher_scores[param] += (param.grad.data.pow(2) * prev_mask[param])\n",
        "\n",
        "    new_mask = {}\n",
        "    all_scores = torch.cat([torch.flatten(v) for v in fisher_scores.values()])\n",
        "    non_zero_scores=all_scores[all_scores!=0]\n",
        "    k = int(sparsity[round] * non_zero_scores.numel())\n",
        "    threshold, _ = torch.kthvalue(non_zero_scores, non_zero_scores.numel()-k)\n",
        "\n",
        "    for param, score in fisher_scores.items():\n",
        "        masked_score = score * prev_mask[param]\n",
        "        current_mask = ((masked_score < threshold) * prev_mask[param]).float()\n",
        "        new_mask[param] = current_mask\n",
        "        prev_mask[param] = new_mask[param]\n",
        "\n",
        "        param_to_name = {param: name for name, param in model.named_parameters()}\n",
        "\n",
        "  for param, mask in new_mask.items():\n",
        "      if torch.any(mask == 1):\n",
        "          print(param_to_name[param])\n",
        "\n",
        "  zero_count = sum((v == 0).sum().item() for v in new_mask.values())\n",
        "  one_count = sum((v == 1).sum().item() for v in new_mask.values())\n",
        "\n",
        "  print(f\"Zeros: {zero_count}, Ones: {one_count}\")\n",
        "\n",
        "  return new_mask"
      ],
      "metadata": {
        "id": "PtV8SqIkeFkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#self implementation of SGDM with the addition of the mask\n",
        "def sgdm_sparse (params, lr, momentum, dampening, weight_decay, nesterov, maximize,b, mask):\n",
        "    for param in params:\n",
        "        if param.grad is None:\n",
        "            continue\n",
        "        grad = param.grad.data\n",
        "\n",
        "        if weight_decay!= 0:\n",
        "          grad=grad+weight_decay*param.data\n",
        "\n",
        "        if param not in b:\n",
        "          b[param] = torch.zeros_like(param.data)\n",
        "\n",
        "        if momentum!=0:\n",
        "            b_toll = b[param]\n",
        "            b_new = momentum * b_toll + (1 - dampening) * grad\n",
        "            if nesterov:\n",
        "               update=grad+momentum*b_new\n",
        "            else:\n",
        "              update=b_new\n",
        "        else:\n",
        "           update=grad\n",
        "           b_new=0\n",
        "\n",
        "        update = update * mask[param]\n",
        "\n",
        "        if maximize:\n",
        "          param.data=param.data+lr*update\n",
        "          b[param] = b_new\n",
        "        else:\n",
        "          param.data=param.data-lr*update\n",
        "          b[param] = b_new\n",
        "    return b"
      ],
      "metadata": {
        "id": "rFrTZIvp-eew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sgd_sparse(epoch, model, train_loader, criterion,sparsity, lr, momentum, weight_decay, mask):\n",
        "     model.train()\n",
        "     running_loss = 0.0\n",
        "     correct = 0\n",
        "     total = 0\n",
        "     params=list(model.parameters())\n",
        "     dampening=0\n",
        "     nesterov=False\n",
        "     maximize=False\n",
        "     b={}\n",
        "\n",
        "     for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "        features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "        outputs = model.head(features)\n",
        "\n",
        "        loss=criterion(outputs, targets)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        b=sgdm_sparse(params, lr, momentum, dampening, weight_decay, nesterov, maximize,b, mask)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "     train_loss = running_loss / len(train_loader)\n",
        "     train_accuracy = 100. * correct / total\n",
        "     print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "lTEv7hdU-eMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre-training only the head\n",
        "num_epochs=5\n",
        "\n",
        "vits16_sparse=copy.deepcopy(vits16_new)\n",
        "optimizer = torch.optim.SGD(vits16_sparse.head.parameters(), lr=1e-4, momentum=0.9, weight_decay=5e-4)\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "  train(epoch, vits16_sparse, train_loader, loss_fn, optimizer)\n",
        "  validate(vits16_sparse, test_loader, loss_fn)"
      ],
      "metadata": {
        "id": "ffME-PKppjq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mask computation\n",
        "train_subset = torch.utils.data.Subset(train_val, train_indices)\n",
        "num_samples = int(0.1 * len(train_subset))\n",
        "small_train_indices = list(range(num_samples))\n",
        "small_train = torch.utils.data.Subset(train_subset, small_train_indices)\n",
        "small_train_loader = torch.utils.data.DataLoader(small_train, batch_size=1, shuffle=True)\n",
        "\n",
        "sparsity=[0.1, 0.2, 0.3, 0.4, 0.66]\n",
        "mask = compute_fisher_mask(vits16_sparse, small_train_loader, sparsity, loss_fn)"
      ],
      "metadata": {
        "id": "rIULqeLcQtUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Sparse SGDM\n",
        "test_loss_vector_sparse=[]\n",
        "num_epochs=200\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    train_sgd_sparse(epoch, vits16_sparse, train_loader, loss_fn,sparsity, lr=1e-4, momentum=0.9, weight_decay=5e-4, mask=mask)\n",
        "    test_accuracy_sparse, test_loss_sparse = validate(vits16_sparse, test_loader, loss_fn)\n",
        "    test_loss_vector_sparse.append(test_loss_sparse)"
      ],
      "metadata": {
        "id": "xWI45yLHkXcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(test_loss_vector_sparse, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, num_epochs, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, num_epochs, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels, fontsize=8)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test_loss Weight decay=5e-4, Learning rate=1e-4, Momentum=0.9')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pBW27d-3quFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}