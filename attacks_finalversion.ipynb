{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescaMusella/MLDL-Project/blob/main/attacks_finalversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbmbDiFwvwnh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch import nn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqmh_PBIwndd"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XH7fLADwqfW"
      },
      "outputs": [],
      "source": [
        "#Transformation of CIFAR100 dataset\n",
        "transform = T.Compose([\n",
        "    T.Resize((32, 32)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5GfsUjawt7p",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "train_val=CIFAR100(root='.data/', train=True, download=True, transform=transform)\n",
        "test=CIFAR100(root='.data/', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48yl_4yCww_B"
      },
      "outputs": [],
      "source": [
        "#train-validation-test split\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "targets = train_val.targets\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(targets)),\n",
        "    test_size=0.1,\n",
        "    stratify=targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val = torch.utils.data.Subset(train_val, val_indices)\n",
        "val_loader= torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPTCEsN_3vqv"
      },
      "outputs": [],
      "source": [
        "#non I.I.D balanced dataset definition\n",
        "def create_balanced_dataset(N, K, num_class, train_indices, train_val):\n",
        "   num_clients=K\n",
        "   num_class_client=N\n",
        "   mat_clients=np.full((num_clients,num_class_client), -1)\n",
        "   toll=0\n",
        "   nDisp=list(range(num_class))\n",
        "   nUtil= np.zeros(num_class, dtype=int)\n",
        "\n",
        "   for i in range(num_clients):\n",
        "     for j in range(num_class_client):\n",
        "        toll=random.choice(nDisp)\n",
        "        mat_clients[i,j]=toll\n",
        "        nDisp.remove(toll)\n",
        "        if len(nDisp)==0:\n",
        "          nDisp=list(range(num_class))\n",
        "\n",
        "   values, counts = np.unique(mat_clients, return_counts=True)\n",
        "\n",
        "   class_to_indices = defaultdict(list)\n",
        "   for idx in train_indices:\n",
        "      label = train_val.targets[idx]\n",
        "      class_to_indices[label].append(idx)\n",
        "\n",
        "   for cls in class_to_indices:\n",
        "      random.shuffle(class_to_indices[cls])\n",
        "\n",
        "   client_indices_list = []\n",
        "   client_indices_list_mask = []\n",
        "   client_dataset = []\n",
        "   client_dataset_mask=[]\n",
        "   client_loader = []\n",
        "   client_loader_mask=[]\n",
        "\n",
        "   numel_per_classclient = int(len(train_indices)/(num_class*N))\n",
        "\n",
        "   for client_id in range(K):\n",
        "      class_client = mat_clients[client_id]\n",
        "      indices_client = []\n",
        "      indices_client_mask=[]\n",
        "\n",
        "      for cls in class_client:\n",
        "         indices_cls = class_to_indices[cls]\n",
        "         sampled = indices_cls[0:numel_per_classclient]\n",
        "\n",
        "         sampled_mask=indices_cls[0:int(numel_per_classclient*0.15)]\n",
        "\n",
        "         class_to_indices[cls] = class_to_indices[cls][numel_per_classclient:]\n",
        "         indices_client.extend(sampled)\n",
        "\n",
        "         indices_client_mask.extend(sampled_mask)\n",
        "\n",
        "      client_indices_list.append(indices_client)\n",
        "      client_dataset.append(torch.utils.data.Subset(train_val, indices_client))\n",
        "      client_loader.append(torch.utils.data.DataLoader(client_dataset[-1], batch_size=32, shuffle=True))\n",
        "\n",
        "      client_indices_list_mask.append(indices_client_mask)\n",
        "      client_dataset_mask.append(torch.utils.data.Subset(train_val, indices_client_mask))\n",
        "      client_loader_mask.append(torch.utils.data.DataLoader(client_dataset_mask[-1], batch_size=1, shuffle=True))\n",
        "\n",
        "   return client_indices_list,client_dataset,client_loader, client_loader_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_i9ZsDv40rM"
      },
      "outputs": [],
      "source": [
        "#non I.I.D balanced dataset creation\n",
        "N=10\n",
        "K=100\n",
        "num_class=int(len(set(targets)))\n",
        "client_noniid,client_dataset_noniid,client_loader_noniid, client_loader_mask_noniid=create_balanced_dataset(N, K, num_class, train_indices, train_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4RWJILyw-RO"
      },
      "outputs": [],
      "source": [
        "#ViT-S/16\n",
        "!git clone https://github.com/facebookresearch/dino.git\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7ZXQDuaxE6u"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "vits16_original = torch.hub.load('facebookresearch/dino:main', 'dino_vits16', pretrained=True).to(device)\n",
        "vits16_new=copy.deepcopy(vits16_original)\n",
        "print(vits16_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EevkPlDxF1E"
      },
      "outputs": [],
      "source": [
        "#Change of the head and freezing of layers\n",
        "vits16_new.head = torch.nn.Linear(in_features=384,\n",
        "                    out_features=100,\n",
        "                    bias=True).to(device)\n",
        "\n",
        "for name, param in vits16_new.named_parameters():\n",
        "    if \"head\" not in name and \"patch_embed\" not in name and 'proj' not in name and 'pos_drop' not in name and 'attn' not in name:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbkoA2xnxZIv"
      },
      "outputs": [],
      "source": [
        "def FedAvg(model, K, C, J, T, lr, momentum, weight_decay, loss_fn, client_loader, trainable_part, implementation,  client_loader_mask, test_loader,  adversarial_clients, attack, test, attack_mask):\n",
        "  global_params = model.state_dict()\n",
        "\n",
        "  val_acc_fed_list=[]\n",
        "  val_loss_fed_list=[]\n",
        "  val_acc_fed_attack_list=[]\n",
        "  val_loss_fed_attack_list=[]\n",
        "\n",
        "  for t in range(T):\n",
        "      client_samples=random.sample(range(K), int(max(1, K*C)))\n",
        "      local_params = []\n",
        "      client_num_samples = []\n",
        "\n",
        "      for client in client_samples:\n",
        "          model_client=copy.deepcopy(model)\n",
        "          num_samples = len(client_loader[client].dataset)\n",
        "          client_num_samples.append(num_samples)\n",
        "\n",
        "          if trainable_part == 'head':\n",
        "              optimizer = torch.optim.SGD(model_client.head.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "          else:\n",
        "              optimizer = torch.optim.SGD(model_client.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "\n",
        "          if implementation=='self':\n",
        "                    sparsity=[0.1, 0.2, 0.3, 0.4, 0.66]\n",
        "                    mask_fed=compute_fisher_mask(model_client,  client_loader_mask[client], sparsity, loss_fn, attack_mask, adversarial_clients, client)\n",
        "\n",
        "          for loc_step in range(J):\n",
        "              batch_idx=torch.randint(0, len(client_loader[client]), (1,)).item()\n",
        "              for i, (inputs, labels) in enumerate(client_loader[client]):\n",
        "                  if i == batch_idx:\n",
        "                      inputs_client=inputs\n",
        "                      labels_client=labels\n",
        "                      break\n",
        "\n",
        "              if implementation=='self':\n",
        "                    train_sgd_sparse(loc_step, model_client, inputs_client, labels_client, loss_fn, lr, momentum, weight_decay, mask_fed,  adversarial_clients, client, attack)\n",
        "\n",
        "              else:\n",
        "                    train(loc_step, model_client, inputs_client, labels_client, loss_fn, optimizer,J,client, attack)\n",
        "\n",
        "          local_params.append(model_client.state_dict())\n",
        "\n",
        "      total_samples = sum(client_num_samples)\n",
        "\n",
        "      new_global_params = copy.deepcopy(global_params)\n",
        "      for key in global_params.keys():\n",
        "            new_global_params[key] = sum(local_params[i][key].float() * (client_num_samples[i] / total_samples) for i in range(len(client_samples)))\n",
        "\n",
        "      model.load_state_dict(new_global_params)\n",
        "      global_params = new_global_params\n",
        "\n",
        "      if test:\n",
        "        val_acc_fed, val_loss_fed=validate(model, test_loader, loss_fn, test)\n",
        "        if trainable_part != 'head':\n",
        "            val_acc_fed_attack, val_loss_fed_attack=validate_attack(model, test_loader, loss_fn,test)\n",
        "      else:\n",
        "        val_acc_fed, val_loss_fed=validate(model, val_loader, loss_fn, test)\n",
        "        if trainable_part != 'head':\n",
        "            val_acc_fed_attack, val_loss_fed_attack=validate_attack(model, val_loader, loss_fn,test)\n",
        "\n",
        "      val_acc_fed_list.append(val_acc_fed)\n",
        "      val_loss_fed_list.append(val_loss_fed)\n",
        "\n",
        "      if trainable_part != 'head':\n",
        "           val_acc_fed_attack_list.append(val_acc_fed_attack)\n",
        "           val_loss_fed_attack_list.append(val_loss_fed_attack)\n",
        "\n",
        "      print(f'Iteration {t}-------------------')\n",
        "\n",
        "  return val_acc_fed_list, val_loss_fed_list, val_acc_fed_attack_list, val_loss_fed_attack_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7HZ7LK4xZ_k"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, inputs, targets, criterion, optimizer,J,client, attack):\n",
        "    model.train()\n",
        "    lamb=0.25\n",
        "\n",
        "    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "    features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "    outputs = model.head(features)\n",
        "\n",
        "    loss=criterion(outputs, targets)\n",
        "\n",
        "    if attack:\n",
        "        inputs_adv = fgsm_attack_local(model, inputs, targets, criterion, epsilon=0.03)\n",
        "        intermediate_output_adv = model.get_intermediate_layers(inputs_adv, n=1)\n",
        "        features_adv = torch.cat([x[:, 0] for x in intermediate_output_adv], dim=-1)\n",
        "        outputs_adv = model.head(features_adv)\n",
        "\n",
        "        loss_adv=criterion(outputs_adv, targets)\n",
        "        loss=lamb*loss+(1-lamb)*loss_adv\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch==J-1:\n",
        "        running_loss = loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total = targets.size(0)\n",
        "        correct = predicted.eq(targets).sum().item()\n",
        "\n",
        "        train_loss = running_loss\n",
        "        train_accuracy = 100. * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASL2CuW7xc8u"
      },
      "outputs": [],
      "source": [
        "#Definition of the function for test performance on normal images\n",
        "def validate(model, val_loader, criterion, test):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "            features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "            outputs = model.head(features)\n",
        "            loss=criterion(outputs, targets)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100. * correct / total\n",
        "    print(f'Validation Loss: {val_loss:.6f} Acc: {val_accuracy:.2f}%')\n",
        "    return val_accuracy, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWiOG-IyWHxy"
      },
      "outputs": [],
      "source": [
        "#Definition of the function for test performance on adversarial images\n",
        "def validate_attack(model, val_loader, criterion,test):\n",
        "    model.eval()\n",
        "    val_loss_attack = 0\n",
        "    correct_attack = 0\n",
        "    total_attack = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            inputs_attack = fgsm_attack_local(model, inputs, targets, criterion, epsilon=0.03)\n",
        "            intermediate_output_attack = model.get_intermediate_layers(inputs_attack, n=1)\n",
        "            features_attack = torch.cat([x[:, 0] for x in intermediate_output_attack], dim=-1)\n",
        "            outputs_attack = model.head(features_attack)\n",
        "            loss_attack=criterion(outputs_attack, targets)\n",
        "\n",
        "            val_loss_attack += loss_attack.item()\n",
        "            _, predicted_attack = outputs_attack.max(1)\n",
        "            total_attack += targets.size(0)\n",
        "            correct_attack += predicted_attack.eq(targets).sum().item()\n",
        "\n",
        "    val_loss_attack = val_loss_attack / len(val_loader)\n",
        "    val_accuracy_attack = 100. * correct_attack / total_attack\n",
        "    print(f'Validation Loss Attack: {val_loss_attack:.6f} Acc: {val_accuracy_attack:.2f}%')\n",
        "\n",
        "    return val_accuracy_attack, val_loss_attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P-cqpZhx5Xi"
      },
      "outputs": [],
      "source": [
        "#creation of the mask\n",
        "def compute_fisher_mask(model, dataloader, sparsity, criterion, attack_mask, adversarial_clients, client_id):\n",
        "  fisher_scores = {}\n",
        "  prev_mask = {}\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for param in model.head.parameters():\n",
        "    param.requires_grad= False\n",
        "\n",
        "  for param in model.parameters():\n",
        "      if param.requires_grad:\n",
        "          fisher_scores[param] = torch.zeros_like(param.data)\n",
        "          prev_mask[param] = torch.ones_like(param.data)\n",
        "\n",
        "  for round in range(5):\n",
        "    for param in fisher_scores:\n",
        "        fisher_scores[param].zero_()\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "        if attack_mask: #attack in the creation of the mask\n",
        "           if adversarial_clients and client_id in adversarial_clients:\n",
        "              inputs = fgsm_attack_local(model, inputs, targets, criterion, epsilon=0.03)\n",
        "\n",
        "        intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "        features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "        outputs = model.head(features)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        for param in model.parameters():\n",
        "            if param.requires_grad and param.grad is not None:\n",
        "              fisher_scores[param] += (param.grad.data.pow(2) * prev_mask[param])\n",
        "\n",
        "    new_mask = {}\n",
        "    all_scores = torch.cat([torch.flatten(v) for v in fisher_scores.values()])\n",
        "    non_zero_scores=all_scores[all_scores!=0]\n",
        "    k = int(sparsity[round] * non_zero_scores.numel())\n",
        "    threshold, _ = torch.kthvalue(non_zero_scores, non_zero_scores.numel()-k)\n",
        "\n",
        "    for param, score in fisher_scores.items():\n",
        "\n",
        "        masked_score = score * prev_mask[param]\n",
        "        current_mask = ((masked_score < threshold) * prev_mask[param]).float()\n",
        "        new_mask[param] = current_mask\n",
        "        prev_mask[param] = new_mask[param]\n",
        "\n",
        "  return new_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-rlnjVGx6U0"
      },
      "outputs": [],
      "source": [
        "#self implementation of SGDM with the addition of the mask\n",
        "def sgdm_sparse (params, lr, momentum, dampening, weight_decay, nesterov, maximize,b, mask):\n",
        "    for param in params:\n",
        "        if param.grad is None:\n",
        "            continue\n",
        "        grad = param.grad.data\n",
        "\n",
        "        if weight_decay!= 0:\n",
        "          grad=grad+weight_decay*param.data\n",
        "\n",
        "        if param not in b:\n",
        "          b[param] = torch.zeros_like(param.data)\n",
        "\n",
        "        if momentum!=0:\n",
        "            b_toll = b[param]\n",
        "            b_new = momentum * b_toll + (1 - dampening) * grad\n",
        "            if nesterov:\n",
        "               update=grad+momentum*b_new\n",
        "            else:\n",
        "              update=b_new\n",
        "        else:\n",
        "           update=grad\n",
        "           b_new=0\n",
        "\n",
        "        update = update * mask[param]\n",
        "\n",
        "        if maximize:\n",
        "          param.data=param.data+lr*update\n",
        "          b[param] = b_new\n",
        "        else:\n",
        "          param.data=param.data-lr*update\n",
        "          b[param] = b_new\n",
        "    return b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLLgLOmNubg3"
      },
      "outputs": [],
      "source": [
        "def train_sgd_sparse(epoch, model, inputs, targets, criterion, lr, momentum, weight_decay, mask, adversarial_clients, client_id, attack):\n",
        "     model.train()\n",
        "     running_loss = 0.0\n",
        "     correct = 0\n",
        "     total = 0\n",
        "     params=list(model.parameters())\n",
        "     dampening=0\n",
        "     nesterov=False\n",
        "     maximize=False\n",
        "     b={}\n",
        "\n",
        "     inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "     if attack:  #attack at train time\n",
        "        if adversarial_clients and client_id in adversarial_clients:\n",
        "           inputs = fgsm_attack_local(model, inputs, targets, criterion, epsilon=0.03)\n",
        "\n",
        "     intermediate_output = model.get_intermediate_layers(inputs, n=1)\n",
        "     features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "     outputs = model.head(features)\n",
        "\n",
        "     loss=criterion(outputs, targets)\n",
        "     model.zero_grad()\n",
        "     loss.backward()\n",
        "\n",
        "     b=sgdm_sparse(params, lr, momentum, dampening, weight_decay, nesterov, maximize,b, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unqjyYRtJYVM"
      },
      "outputs": [],
      "source": [
        "#definition of FGSM attack\n",
        "def fgsm_attack_local(model, images, labels, criterion, epsilon=0.03):\n",
        "\n",
        "    images = images.clone().detach().to(images.device)\n",
        "    labels = labels.to(images.device)\n",
        "    images.requires_grad = True\n",
        "\n",
        "    intermediate_output = model.get_intermediate_layers(images, n=1)\n",
        "    features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
        "    outputs = model.head(features)\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    grad = images.grad.data\n",
        "    adv_images = images + epsilon * grad.sign()\n",
        "    adv_images = torch.clamp(adv_images, 0, 1)\n",
        "\n",
        "    return adv_images.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCUXtfskexno"
      },
      "outputs": [],
      "source": [
        "# Strong Baseline: adversarial training without mask\n",
        "K = 100\n",
        "C = 0.1\n",
        "J = 8\n",
        "momentum = 0\n",
        "weight_decay = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "vits16_adv_train=copy.deepcopy(vits16_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gme5cj6EfNu4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "adversarial_clients=list(range(0, K)) #all clients are attackers\n",
        "lr = 1e-3\n",
        "T=200\n",
        "val_acc_fed_list_adv, val_loss_fed_list_adv, val_acc_fed_attack_list_adv, val_loss_fed_attack_list_adv=FedAvg(vits16_adv_train, K, C, J, T, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='full', implementation='pyt', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=True, test=True, attack_mask=False)\n",
        "print(f'Test for non i.i.d.balanced dataset with with N={N} and J={J}')\n",
        "validate(vits16_adv_train, test_loader, loss_fn,test=True)\n",
        "validate_attack(vits16_adv_train, test_loader, loss_fn, test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtQiQJPtWk5q"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on original images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_list_adv, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(19, T, 20) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(19, T, 20) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDGfqqTVWxCS"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on perturbed images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_attack_list_adv, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(19, T, 20) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(19, T, 20) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss attack')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAMxRLyaQKo_"
      },
      "outputs": [],
      "source": [
        "#portion of attackers\n",
        "adversarial_clients = random.sample(range(K), 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--5_QsxI6EYr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Attacks only at test time\n",
        "K = 100\n",
        "C = 0.1\n",
        "J = 8\n",
        "momentum = 0\n",
        "weight_decay = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 1e-2\n",
        "T_head=40\n",
        "\n",
        "vits16_mask=copy.deepcopy(vits16_new)\n",
        "FedAvg(vits16_mask, K, C, J, T_head, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='head', implementation='pyt', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=False, test=False, attack_mask=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PltgmLuJmO2J",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "lr = 5e-3\n",
        "T= 30\n",
        "val_acc_fed_list, val_loss_fed_list, val_acc_fed_attack_list, val_loss_fed_attack_list=FedAvg(vits16_mask, K, C, J, T, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='full', implementation='self', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=False, test=True, attack_mask=False)\n",
        "print(f'Test for non i.i.d.balanced dataset with with N={N} and J={J}')\n",
        "validate(vits16_mask, test_loader, loss_fn, test=True)\n",
        "validate_attack(vits16_mask, test_loader, loss_fn, test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqpNlQ9DUdlR"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on original images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_list, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YVaPRfJVrGU"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on perturbed images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_attack_list, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss attack')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOpUDhPmbBlQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Attacks at train and test time\n",
        "K = 100\n",
        "C = 0.1\n",
        "J = 8\n",
        "momentum = 0\n",
        "weight_decay = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 1e-2\n",
        "T_head=40\n",
        "\n",
        "vits16_mask_attack=copy.deepcopy(vits16_new)\n",
        "FedAvg(vits16_mask_attack, K, C, J, T_head, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='head', implementation='pyt', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=False, test=False, attack_mask=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Dr3CJucdf-4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "lr = 5e-3\n",
        "T=30\n",
        "val_acc_fed_list_partial, val_loss_fed_list_partial, val_acc_fed_attack_list_partial, val_loss_fed_attack_list_partial=FedAvg(vits16_mask_attack, K, C, J, T, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='full', implementation='self', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=True, test=True, attack_mask=False)\n",
        "\n",
        "print(f'Test for non i.i.d.balanced dataset with with N={N} and J={J}')\n",
        "validate(vits16_mask_attack, test_loader, loss_fn, test=True)\n",
        "validate_attack(vits16_mask_attack, test_loader, loss_fn, test=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDDZOKj-V8k0"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on original images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_list_partial, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY_3s6dlV_31"
      },
      "outputs": [],
      "source": [
        "#Test loss plot on perturbed images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_attack_list_partial, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss attack')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A20GJBU9eU3W",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Attacks in the creation of the mask, at train and test time\n",
        "K = 100\n",
        "C = 0.1\n",
        "J = 8\n",
        "momentum = 0\n",
        "weight_decay = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 1e-2\n",
        "T_head=40\n",
        "\n",
        "vits16_mask_train_attack=copy.deepcopy(vits16_new)\n",
        "FedAvg(vits16_mask_train_attack, K, C, J, T_head, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='head', implementation='pyt', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=False, test=False, attack_mask=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 5e-3\n",
        "T=30\n",
        "val_acc_fed_list_mask_train, val_loss_fed_list_mask_train, val_acc_fed_attack_list_mask_train, val_loss_fed_attack_list_mask_train=FedAvg(vits16_mask_train_attack, K, C, J, T, lr, momentum, weight_decay,loss_fn, client_loader_noniid, trainable_part='full', implementation='self', client_loader_mask=client_loader_mask_noniid, test_loader=test_loader, adversarial_clients=adversarial_clients, attack=True, test=True, attack_mask=True)\n",
        "\n",
        "print(f'Test for non i.i.d.balanced dataset with with N={N} and J={J}')\n",
        "validate(vits16_mask_train_attack, test_loader, loss_fn, test=True)\n",
        "validate_attack(vits16_mask_train_attack, test_loader, loss_fn, test=True)"
      ],
      "metadata": {
        "id": "GKco73c83tex",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test loss plot on original images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_list_mask_train, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hE0sjIiZ4uFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test loss plot on perturbed images\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.plot(val_loss_fed_attack_list_mask_train, label='Test Loss')\n",
        "ticks = [0] + [i for i in range(4, T, 5) if i != 0]\n",
        "labels = [1] + [i + 1 for i in range(4, T, 5) if i != 0]\n",
        "plt.xticks(ticks=ticks, labels=labels)\n",
        "plt.xlabel('Rounds')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.title('Test loss attack')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "068vKFJt4xc_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}